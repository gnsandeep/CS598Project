{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "similar-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-drinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "focused-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emerging-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize(224),\n",
    "            # because scale doesn't always give 224 x 224, this ensures 224 x\n",
    "            # 224\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "found-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path_to_images,labelcsv,transform=None):\n",
    "\n",
    "        self.transform = transform\n",
    "        self.path_to_images = path_to_images\n",
    "        self.df = pd.read_csv(labelcsv)\n",
    "\n",
    "        self.df = self.df.set_index(\"Image Index\")\n",
    "        self.PRED_LABEL = [\n",
    "            'Atelectasis',\n",
    "            'Cardiomegaly',\n",
    "            'Effusion',\n",
    "            'Infiltration',\n",
    "            'Mass',\n",
    "            'Nodule',\n",
    "            'Pneumonia',\n",
    "            'Pneumothorax',\n",
    "            'Consolidation',\n",
    "            'Edema',\n",
    "            'Emphysema',\n",
    "            'Fibrosis',\n",
    "            'Pleural_Thickening',\n",
    "            'Hernia']\n",
    "\n",
    "        RESULT_PATH = \"results/\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(\n",
    "            os.path.join(\n",
    "                self.path_to_images,\n",
    "                self.df.index[idx]))\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "        label = np.zeros(len(self.PRED_LABEL), dtype=int)\n",
    "        for i in range(0, len(self.PRED_LABEL)):\n",
    "            if(self.df[self.PRED_LABEL[i].strip()].iloc[idx].astype('int') > 0):\n",
    "                label[i] = self.df[self.PRED_LABEL[i].strip()\n",
    "                                   ].iloc[idx].astype('int')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, label,self.df.index[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supported-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path=None):\n",
    "\n",
    "    data_train = CustomDataset(\n",
    "        path_to_images='/home/ubuntu/payload/NIHData/images/',\n",
    "        labelcsv = 'train_0.1.csv',\n",
    "        transform=data_transforms['train'])\n",
    "    data_val = CustomDataset(\n",
    "        path_to_images='/home/ubuntu/payload/NIHData/images/',\n",
    "        labelcsv = 'val-small_0.1.csv',\n",
    "        transform=data_transforms['val'])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader , data_train , data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "therapeutic-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: Define the CNN model here. \n",
    "        We will use the pretrained ResNet18 model, which can be initialized with torchvision.models.resnet18\n",
    "        Then, replace the last layer (model.fc) with a nn.Linear layer\n",
    "            The new model.fc should have the same input size but a new output_size of 2\n",
    "    \"\"\"\n",
    "\n",
    "    from torchvision import models\n",
    "\n",
    "    num_classes = 14\n",
    "    # your code here\n",
    "    #raise NotImplementedError\n",
    "    #old code model = torchvision.models.resnet18()\n",
    "    model = models.densenet121(pretrained=False)\n",
    "    #old code num_ftrs = model.fc.in_features\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, num_classes), nn.Sigmoid())\n",
    "    # old code model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    #For computation efficiency, we will freeze the weights in the bottom layers\n",
    "    #If it's too slow, you can turn off layer4's weights update as well\n",
    "    '''\n",
    "    for param in model.named_parameters():\n",
    "        if param[0].split(\".\")[0] in {'fc', 'layer4'}: continue\n",
    "        param[1].requires_grad = False'''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "religious-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model()\n",
    "model.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "LR = 0.01\n",
    "optimizer = torch.optim.SGD(\n",
    "        filter(\n",
    "            lambda p: p.requires_grad,\n",
    "            model.parameters()),\n",
    "        lr=LR,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "viral-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "def train_model(model, train_dataloader, val_dataloader, n_epoch=n_epochs, optimizer=optimizer, criterion=criterion):\n",
    "    import torch.optim as optim\n",
    "    \"\"\"\n",
    "    :param model: A CNN model\n",
    "    :param train_dataloader: the DataLoader of the training data\n",
    "    :param n_epoch: number of epochs to train\n",
    "    :return:\n",
    "        model: trained model\n",
    "    TODO:\n",
    "        Within the loop, do the normal training procedures:\n",
    "            pass the input through the model\n",
    "            pass the output through loss_func to compute the loss (name the variable as *loss*)\n",
    "            zero out currently accumulated gradient, use loss.basckward to backprop the gradients, then call optimizer.step\n",
    "    \"\"\"\n",
    "     # prep model for training\n",
    "    \n",
    "    train_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])\n",
    "    val_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])\n",
    "    best_loss = 999999\n",
    "    LR = 0.01\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        model.train()\n",
    "        train_row={}\n",
    "        train_curr_epoch_loss = []\n",
    "        #for data, target in train_dataloader:\n",
    "        for data in train_dataloader:\n",
    "            # your code here\n",
    "            #inputs, labels, _ = data\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            loss = criterion(y_hat, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            \n",
    "        train_row[\"Epoch No\"] = epoch\n",
    "        train_row[\"Loss\"] = np.mean(train_curr_epoch_loss)\n",
    "        train_epochs_loss = train_epochs_loss.append(train_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Train curr_epoch_loss={np.mean(train_curr_epoch_loss)}\")\n",
    "        \n",
    "        model.eval()\n",
    "        #pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        #true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        val_row={}\n",
    "        \n",
    "        val_curr_epoch_loss = []\n",
    "        for i, data in enumerate(val_dataloader):    \n",
    "            #inputs, labels, _ = data\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            true_labels = labels.cpu().data.numpy()\n",
    "            \n",
    "            #batch_size = true_labels.shape\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            probs = y_hat.cpu().data.numpy()\n",
    "                \n",
    "            \n",
    "            loss = criterion(y_hat, labels)\n",
    "            val_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            '''if epoch == n_epochs-1: \n",
    "\n",
    "                for j in range(0, batch_size[0]):\n",
    "                    thisrow = {}\n",
    "                    truerow = {}\n",
    "                    thisrow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "                    truerow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "\n",
    "                    # iterate over each entry in prediction vector; each corresponds to\n",
    "                    # individual label\n",
    "                    for k in range(len(val_dataset.PRED_LABEL)):\n",
    "                        thisrow[\"prob_\" + val_dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                        truerow[val_dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "\n",
    "                pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "                true_df = true_df.append(truerow, ignore_index=True)\n",
    "            '''\n",
    "        val_row[\"Epoch No\"] = epoch\n",
    "        val_row[\"Loss\"] = np.mean(val_curr_epoch_loss)\n",
    "        val_epochs_loss = val_epochs_loss.append(val_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Val curr_epoch_loss={np.mean(val_curr_epoch_loss)}\")\n",
    "        if np.mean(val_curr_epoch_loss) > best_loss:\n",
    "            LR = LR / 10\n",
    "            print(\"Curr Val loss greater than best Val loss , LR : \" , LR)\n",
    "            optimizer = optim.SGD(\n",
    "                    filter(\n",
    "                        lambda p: p.requires_grad,\n",
    "                        model.parameters()),\n",
    "                    lr=LR,\n",
    "                    momentum=0.9,\n",
    "                    weight_decay=1e-4)\n",
    "        if np.mean(val_curr_epoch_loss) < best_loss:\n",
    "            best_loss = np.mean(val_curr_epoch_loss)\n",
    "            print(\"Curr Val loss less than best Val loss , LR : \" , LR)\n",
    "        \n",
    "    return model,train_epochs_loss,val_epochs_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''n_epochs = 12\n",
    "def train_model(model, train_dataloader, val_dataloader, n_epoch=n_epochs, optimizer=optimizer, criterion=criterion):\n",
    "    import torch.optim as optim\n",
    "\n",
    "     # prep model for training\n",
    "    \n",
    "    train_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])\n",
    "    val_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])   \n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        model.train()\n",
    "        train_row={}\n",
    "        train_curr_epoch_loss = []\n",
    "        #for data, target in train_dataloader:\n",
    "        for data in train_dataloader:\n",
    "            # your code here\n",
    "            #inputs, labels, _ = data\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            loss = criterion(y_hat, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            \n",
    "        train_row[\"Epoch No\"] = epoch\n",
    "        train_row[\"Loss\"] = np.mean(train_curr_epoch_loss)\n",
    "        train_epochs_loss = train_epochs_loss.append(train_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Train curr_epoch_loss={np.mean(train_curr_epoch_loss)}\")\n",
    "        \n",
    "        model.eval()\n",
    "        pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        val_row={}\n",
    "        \n",
    "        val_curr_epoch_loss = []\n",
    "        for i, data in enumerate(val_dataloader):    \n",
    "            #inputs, labels, _ = data\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            true_labels = labels.cpu().data.numpy()\n",
    "            \n",
    "            batch_size = true_labels.shape\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            probs = y_hat.cpu().data.numpy()\n",
    "                \n",
    "            \n",
    "            loss = criterion(y_hat, labels)\n",
    "            val_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            if epoch == n_epochs-1: \n",
    "\n",
    "                for j in range(0, batch_size[0]):\n",
    "                    thisrow = {}\n",
    "                    truerow = {}\n",
    "                    thisrow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "                    truerow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "\n",
    "                    # iterate over each entry in prediction vector; each corresponds to\n",
    "                    # individual label\n",
    "                    for k in range(len(val_dataset.PRED_LABEL)):\n",
    "                        thisrow[\"prob_\" + val_dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                        truerow[val_dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "\n",
    "                pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "                true_df = true_df.append(truerow, ignore_index=True)\n",
    "            \n",
    "        val_row[\"Epoch No\"] = epoch\n",
    "        val_row[\"Loss\"] = np.mean(val_curr_epoch_loss)\n",
    "        val_epochs_loss = val_epochs_loss.append(val_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Val curr_epoch_loss={np.mean(val_curr_epoch_loss)}\")\n",
    "        \n",
    "    return model,pred_df,true_df,train_epochs_loss,val_epochs_loss\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "temporal-subdivision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train curr_epoch_loss=0.1952492594718933\n",
      "Epoch 0: Val curr_epoch_loss=0.17661850154399872\n",
      "Curr Val loss less than best Val loss , LR :  0.01\n",
      "Epoch 1: Train curr_epoch_loss=0.17751161754131317\n",
      "Epoch 1: Val curr_epoch_loss=0.1748473048210144\n",
      "Curr Val loss less than best Val loss , LR :  0.01\n",
      "Epoch 2: Train curr_epoch_loss=0.17563246190547943\n",
      "Epoch 2: Val curr_epoch_loss=0.17362083494663239\n",
      "Curr Val loss less than best Val loss , LR :  0.01\n",
      "Epoch 3: Train curr_epoch_loss=0.17462210357189178\n",
      "Epoch 3: Val curr_epoch_loss=0.17240485548973083\n",
      "Curr Val loss less than best Val loss , LR :  0.01\n",
      "Epoch 4: Train curr_epoch_loss=0.17352165281772614\n",
      "Epoch 4: Val curr_epoch_loss=0.17251773178577423\n",
      "Curr Val loss greater than best Val loss , LR :  0.001\n",
      "Epoch 5: Train curr_epoch_loss=0.17181329429149628\n",
      "Epoch 5: Val curr_epoch_loss=0.17113478481769562\n",
      "Curr Val loss less than best Val loss , LR :  0.001\n",
      "Epoch 6: Train curr_epoch_loss=0.17134788632392883\n",
      "Epoch 6: Val curr_epoch_loss=0.17085669934749603\n",
      "Curr Val loss less than best Val loss , LR :  0.001\n",
      "Epoch 7: Train curr_epoch_loss=0.17153842747211456\n",
      "Epoch 7: Val curr_epoch_loss=0.170786514878273\n",
      "Curr Val loss less than best Val loss , LR :  0.001\n",
      "Epoch 8: Train curr_epoch_loss=0.17109672725200653\n",
      "Epoch 8: Val curr_epoch_loss=0.1706232726573944\n",
      "Curr Val loss less than best Val loss , LR :  0.001\n",
      "Epoch 9: Train curr_epoch_loss=0.1713007688522339\n",
      "Epoch 9: Val curr_epoch_loss=0.17073982954025269\n",
      "Curr Val loss greater than best Val loss , LR :  0.0001\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader , train_dataset , val_dataset = load_data()\n",
    "model,train_epochs_loss,val_epochs_loss = train_model(model, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boxed-latex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = train_epochs_loss['Loss']\n",
    "loss_val = val_epochs_loss['Loss']\n",
    "epochs = val_epochs_loss['Epoch No']\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brilliant-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "        Y_pred: prediction of model on the dataloder.\n",
    "            Should be an 2D numpy float array where the second dimension has length 2.\n",
    "        Y_test: truth labels. Should be an numpy array of ints\n",
    "    TODO:\n",
    "        evaluate the model using on the data in the dataloder.\n",
    "        Add all the prediction and truth to the corresponding list\n",
    "        Convert Y_pred and Y_test to numpy arrays (of shape (n_data_points, 2))\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    #Y_pred = []\n",
    "    #Y_test = []\n",
    "    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "    true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "    #for data, target in dataloader:\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # your code here\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        #inputs, labels, _ = data\n",
    "        true_labels = labels.cpu().data.numpy()\n",
    "        batch_size = true_labels.shape\n",
    "        #print(\"batch_size : \" , batch_size)\n",
    "        y_hat = model(inputs)\n",
    "        probs = y_hat.cpu().data.numpy()\n",
    "        #y_hat = model(data)\n",
    "        #y_hat_ = torch.max(y_hat,dim=1)\n",
    "        #_, predicted = torch.max(y_hat, 1)\n",
    "        #print(type(y_hat),y_hat)\n",
    "        #print(\"predicted : \" ,type(predicted),predicted.shape)\n",
    "        #print(\"target : \" ,target)\n",
    "        #Y_pred.append(predicted.detach().numpy())\n",
    "        #Y_test.append(target.detach().numpy())\n",
    "        for j in range(0, batch_size[0]):\n",
    "            thisrow = {}\n",
    "            truerow = {}\n",
    "            thisrow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "            truerow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "\n",
    "            # iterate over each entry in prediction vector; each corresponds to\n",
    "            # individual label\n",
    "            for k in range(len(val_dataset.PRED_LABEL)):\n",
    "                thisrow[\"prob_\" + val_dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                truerow[val_dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "\n",
    "            pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "            true_df = true_df.append(truerow, ignore_index=True)\n",
    "\n",
    "        if(i % 10 == 0):\n",
    "            print(str(i * BATCH_SIZE))\n",
    "\n",
    "    #print()\n",
    "        #raise NotImplementedError\n",
    "    #Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "    #Y_test = np.concatenate(Y_test, axis=0)\n",
    "\n",
    "    return pred_df, true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lined-bosnia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "320\n",
      "640\n",
      "960\n",
      "1280\n",
      "1600\n",
      "1920\n",
      "2240\n"
     ]
    }
   ],
   "source": [
    "pred_df, true_df = eval_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mounted-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n",
    "\n",
    "for column in true_df:\n",
    "    #print('---------------------')\n",
    "    #print(\"Column : \" , column)\n",
    "    if column not in [\n",
    "            'Atelectasis',\n",
    "            'Cardiomegaly',\n",
    "            'Effusion',\n",
    "            'Infiltration',\n",
    "            'Mass',\n",
    "            'Nodule',\n",
    "            'Pneumonia',\n",
    "            'Pneumothorax',\n",
    "            'Consolidation',\n",
    "            'Edema',\n",
    "            'Emphysema',\n",
    "            'Fibrosis',\n",
    "            'Pleural_Thickening',\n",
    "                'Hernia']:\n",
    "        continue\n",
    "    actual = true_df[column]\n",
    "    #print( 'Actual : ' , actual)\n",
    "    pred = pred_df[\"prob_\" + column]\n",
    "    #print('Pred : ' , pred)\n",
    "    thisrow = {}\n",
    "    thisrow['label'] = column\n",
    "    thisrow['auc'] = np.nan\n",
    "    try:\n",
    "        thisrow['auc'] = sklm.roc_auc_score(\n",
    "        actual.values.astype(int), pred.values)\n",
    "        #auc_df = auc_df.append(thisrow, ignore_index=True)\n",
    "    #except Exception:\n",
    "        \n",
    "    except BaseException as e:\n",
    "        print(\"can't calculate auc for \" + str(column))\n",
    "        print(e)\n",
    "    auc_df = auc_df.append(thisrow, ignore_index=True)\n",
    "\n",
    "pred_df.to_csv(\"DenseNetpredsSGDMomentum.csv\", index=False)\n",
    "auc_df.to_csv(\"DenseNetaucsSGDMomentum.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-conditioning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvproject_venv",
   "language": "python",
   "name": "dvproject_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
