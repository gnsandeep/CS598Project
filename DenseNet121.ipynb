{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "similar-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-drinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "focused-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emerging-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize(224),\n",
    "            # because scale doesn't always give 224 x 224, this ensures 224 x\n",
    "            # 224\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "found-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path_to_images,labelcsv,transform=None):\n",
    "\n",
    "        self.transform = transform\n",
    "        self.path_to_images = path_to_images\n",
    "        self.df = pd.read_csv(labelcsv)\n",
    "\n",
    "        self.df = self.df.set_index(\"Image Index\")\n",
    "        self.PRED_LABEL = [\n",
    "            'Atelectasis',\n",
    "            'Cardiomegaly',\n",
    "            'Effusion',\n",
    "            'Infiltration',\n",
    "            'Mass',\n",
    "            'Nodule',\n",
    "            'Pneumonia',\n",
    "            'Pneumothorax',\n",
    "            'Consolidation',\n",
    "            'Edema',\n",
    "            'Emphysema',\n",
    "            'Fibrosis',\n",
    "            'Pleural_Thickening',\n",
    "            'Hernia']\n",
    "\n",
    "        RESULT_PATH = \"results/\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(\n",
    "            os.path.join(\n",
    "                self.path_to_images,\n",
    "                self.df.index[idx]))\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "        label = np.zeros(len(self.PRED_LABEL), dtype=int)\n",
    "        for i in range(0, len(self.PRED_LABEL)):\n",
    "            if(self.df[self.PRED_LABEL[i].strip()].iloc[idx].astype('int') > 0):\n",
    "                label[i] = self.df[self.PRED_LABEL[i].strip()\n",
    "                                   ].iloc[idx].astype('int')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, label,self.df.index[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supported-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path=None):\n",
    "\n",
    "    data_train = CustomDataset(\n",
    "        path_to_images='/home/ubuntu/payload/NIHData/images/',\n",
    "        labelcsv = 'train_0.1.csv',\n",
    "        transform=data_transforms['train'])\n",
    "    data_val = CustomDataset(\n",
    "        path_to_images='/home/ubuntu/payload/NIHData/images/',\n",
    "        labelcsv = 'val-small_0.1.csv',\n",
    "        transform=data_transforms['val'])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader , data_train , data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "therapeutic-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: Define the CNN model here. \n",
    "        We will use the pretrained ResNet18 model, which can be initialized with torchvision.models.resnet18\n",
    "        Then, replace the last layer (model.fc) with a nn.Linear layer\n",
    "            The new model.fc should have the same input size but a new output_size of 2\n",
    "    \"\"\"\n",
    "\n",
    "    from torchvision import models\n",
    "\n",
    "    num_classes = 14\n",
    "    # your code here\n",
    "    #raise NotImplementedError\n",
    "    #old code model = torchvision.models.resnet18()\n",
    "    model = models.densenet121(pretrained=False)\n",
    "    #old code num_ftrs = model.fc.in_features\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, num_classes), nn.Sigmoid())\n",
    "    # old code model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    #For computation efficiency, we will freeze the weights in the bottom layers\n",
    "    #If it's too slow, you can turn off layer4's weights update as well\n",
    "    '''\n",
    "    for param in model.named_parameters():\n",
    "        if param[0].split(\".\")[0] in {'fc', 'layer4'}: continue\n",
    "        param[1].requires_grad = False'''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "religious-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model()\n",
    "model.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "viral-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "def train_model(model, train_dataloader, val_dataloader, n_epoch=n_epochs, optimizer=optimizer, criterion=criterion):\n",
    "    import torch.optim as optim\n",
    "    \"\"\"\n",
    "    :param model: A CNN model\n",
    "    :param train_dataloader: the DataLoader of the training data\n",
    "    :param n_epoch: number of epochs to train\n",
    "    :return:\n",
    "        model: trained model\n",
    "    TODO:\n",
    "        Within the loop, do the normal training procedures:\n",
    "            pass the input through the model\n",
    "            pass the output through loss_func to compute the loss (name the variable as *loss*)\n",
    "            zero out currently accumulated gradient, use loss.basckward to backprop the gradients, then call optimizer.step\n",
    "    \"\"\"\n",
    "     # prep model for training\n",
    "    \n",
    "    train_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])\n",
    "    val_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])   \n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        model.train()\n",
    "        train_row={}\n",
    "        train_curr_epoch_loss = []\n",
    "        #for data, target in train_dataloader:\n",
    "        for data in train_dataloader:\n",
    "            # your code here\n",
    "            #inputs, labels, _ = data\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            loss = criterion(y_hat, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            \n",
    "        train_row[\"Epoch No\"] = epoch\n",
    "        train_row[\"Loss\"] = np.mean(train_curr_epoch_loss)\n",
    "        train_epochs_loss = train_epochs_loss.append(train_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Train curr_epoch_loss={np.mean(train_curr_epoch_loss)}\")\n",
    "        \n",
    "        model.eval()\n",
    "        #pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        #true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        val_row={}\n",
    "        \n",
    "        val_curr_epoch_loss = []\n",
    "        for i, data in enumerate(val_dataloader):    \n",
    "            #inputs, labels, _ = data\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            true_labels = labels.cpu().data.numpy()\n",
    "            \n",
    "            #batch_size = true_labels.shape\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            probs = y_hat.cpu().data.numpy()\n",
    "                \n",
    "            \n",
    "            loss = criterion(y_hat, labels)\n",
    "            val_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            '''if epoch == n_epochs-1: \n",
    "\n",
    "                for j in range(0, batch_size[0]):\n",
    "                    thisrow = {}\n",
    "                    truerow = {}\n",
    "                    thisrow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "                    truerow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "\n",
    "                    # iterate over each entry in prediction vector; each corresponds to\n",
    "                    # individual label\n",
    "                    for k in range(len(val_dataset.PRED_LABEL)):\n",
    "                        thisrow[\"prob_\" + val_dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                        truerow[val_dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "\n",
    "                pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "                true_df = true_df.append(truerow, ignore_index=True)\n",
    "            '''\n",
    "        val_row[\"Epoch No\"] = epoch\n",
    "        val_row[\"Loss\"] = np.mean(val_curr_epoch_loss)\n",
    "        val_epochs_loss = val_epochs_loss.append(val_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Val curr_epoch_loss={np.mean(val_curr_epoch_loss)}\")\n",
    "        \n",
    "    return model,train_epochs_loss,val_epochs_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''n_epochs = 12\n",
    "def train_model(model, train_dataloader, val_dataloader, n_epoch=n_epochs, optimizer=optimizer, criterion=criterion):\n",
    "    import torch.optim as optim\n",
    "\n",
    "     # prep model for training\n",
    "    \n",
    "    train_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])\n",
    "    val_epochs_loss = pd.DataFrame(columns=[\"Epoch No\",\"Loss\"])   \n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        model.train()\n",
    "        train_row={}\n",
    "        train_curr_epoch_loss = []\n",
    "        #for data, target in train_dataloader:\n",
    "        for data in train_dataloader:\n",
    "            # your code here\n",
    "            #inputs, labels, _ = data\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            loss = criterion(y_hat, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            \n",
    "        train_row[\"Epoch No\"] = epoch\n",
    "        train_row[\"Loss\"] = np.mean(train_curr_epoch_loss)\n",
    "        train_epochs_loss = train_epochs_loss.append(train_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Train curr_epoch_loss={np.mean(train_curr_epoch_loss)}\")\n",
    "        \n",
    "        model.eval()\n",
    "        pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "        val_row={}\n",
    "        \n",
    "        val_curr_epoch_loss = []\n",
    "        for i, data in enumerate(val_dataloader):    \n",
    "            #inputs, labels, _ = data\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "            #labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "            true_labels = labels.cpu().data.numpy()\n",
    "            \n",
    "            batch_size = true_labels.shape\n",
    "            y_hat = model(inputs)\n",
    "            y_hat = y_hat.to(device)\n",
    "            probs = y_hat.cpu().data.numpy()\n",
    "                \n",
    "            \n",
    "            loss = criterion(y_hat, labels)\n",
    "            val_curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            if epoch == n_epochs-1: \n",
    "\n",
    "                for j in range(0, batch_size[0]):\n",
    "                    thisrow = {}\n",
    "                    truerow = {}\n",
    "                    thisrow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "                    truerow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "\n",
    "                    # iterate over each entry in prediction vector; each corresponds to\n",
    "                    # individual label\n",
    "                    for k in range(len(val_dataset.PRED_LABEL)):\n",
    "                        thisrow[\"prob_\" + val_dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                        truerow[val_dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "\n",
    "                pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "                true_df = true_df.append(truerow, ignore_index=True)\n",
    "            \n",
    "        val_row[\"Epoch No\"] = epoch\n",
    "        val_row[\"Loss\"] = np.mean(val_curr_epoch_loss)\n",
    "        val_epochs_loss = val_epochs_loss.append(val_row,ignore_index=True)\n",
    "        print(f\"Epoch {epoch}: Val curr_epoch_loss={np.mean(val_curr_epoch_loss)}\")\n",
    "        \n",
    "    return model,pred_df,true_df,train_epochs_loss,val_epochs_loss\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "temporal-subdivision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train curr_epoch_loss=0.5265325903892517\n",
      "Epoch 0: Val curr_epoch_loss=0.38907191157341003\n",
      "Epoch 1: Train curr_epoch_loss=0.33157822489738464\n",
      "Epoch 1: Val curr_epoch_loss=0.2825319468975067\n",
      "Epoch 2: Train curr_epoch_loss=0.2625654339790344\n",
      "Epoch 2: Val curr_epoch_loss=0.2407851368188858\n",
      "Epoch 3: Train curr_epoch_loss=0.23089586198329926\n",
      "Epoch 3: Val curr_epoch_loss=0.21773985028266907\n",
      "Epoch 4: Train curr_epoch_loss=0.2146482914686203\n",
      "Epoch 4: Val curr_epoch_loss=0.20582301914691925\n",
      "Epoch 5: Train curr_epoch_loss=0.205055832862854\n",
      "Epoch 5: Val curr_epoch_loss=0.2005171924829483\n",
      "Epoch 6: Train curr_epoch_loss=0.19902320206165314\n",
      "Epoch 6: Val curr_epoch_loss=0.19383229315280914\n",
      "Epoch 7: Train curr_epoch_loss=0.19462311267852783\n",
      "Epoch 7: Val curr_epoch_loss=0.18917877972126007\n",
      "Epoch 8: Train curr_epoch_loss=0.19174590706825256\n",
      "Epoch 8: Val curr_epoch_loss=0.18834161758422852\n",
      "Epoch 9: Train curr_epoch_loss=0.18974170088768005\n",
      "Epoch 9: Val curr_epoch_loss=0.18640704452991486\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader , train_dataset , val_dataset = load_data()\n",
    "model,train_epochs_loss,val_epochs_loss = train_model(model, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boxed-latex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = train_epochs_loss['Loss']\n",
    "loss_val = val_epochs_loss['Loss']\n",
    "epochs = val_epochs_loss['Epoch No']\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brilliant-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "        Y_pred: prediction of model on the dataloder.\n",
    "            Should be an 2D numpy float array where the second dimension has length 2.\n",
    "        Y_test: truth labels. Should be an numpy array of ints\n",
    "    TODO:\n",
    "        evaluate the model using on the data in the dataloder.\n",
    "        Add all the prediction and truth to the corresponding list\n",
    "        Convert Y_pred and Y_test to numpy arrays (of shape (n_data_points, 2))\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    #Y_pred = []\n",
    "    #Y_test = []\n",
    "    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "    true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "    #for data, target in dataloader:\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # your code here\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        #inputs, labels, _ = data\n",
    "        true_labels = labels.cpu().data.numpy()\n",
    "        batch_size = true_labels.shape\n",
    "        #print(\"batch_size : \" , batch_size)\n",
    "        y_hat = model(inputs)\n",
    "        probs = y_hat.cpu().data.numpy()\n",
    "        #y_hat = model(data)\n",
    "        #y_hat_ = torch.max(y_hat,dim=1)\n",
    "        #_, predicted = torch.max(y_hat, 1)\n",
    "        #print(type(y_hat),y_hat)\n",
    "        #print(\"predicted : \" ,type(predicted),predicted.shape)\n",
    "        #print(\"target : \" ,target)\n",
    "        #Y_pred.append(predicted.detach().numpy())\n",
    "        #Y_test.append(target.detach().numpy())\n",
    "        for j in range(0, batch_size[0]):\n",
    "            thisrow = {}\n",
    "            truerow = {}\n",
    "            thisrow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "            truerow[\"Image Index\"] = val_dataset.df.index[BATCH_SIZE * i + j]\n",
    "\n",
    "            # iterate over each entry in prediction vector; each corresponds to\n",
    "            # individual label\n",
    "            for k in range(len(val_dataset.PRED_LABEL)):\n",
    "                thisrow[\"prob_\" + val_dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                truerow[val_dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "\n",
    "            pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "            true_df = true_df.append(truerow, ignore_index=True)\n",
    "\n",
    "        if(i % 10 == 0):\n",
    "            print(str(i * BATCH_SIZE))\n",
    "\n",
    "    #print()\n",
    "        #raise NotImplementedError\n",
    "    #Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "    #Y_test = np.concatenate(Y_test, axis=0)\n",
    "\n",
    "    return pred_df, true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lined-bosnia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "320\n",
      "640\n",
      "960\n",
      "1280\n",
      "1600\n",
      "1920\n",
      "2240\n"
     ]
    }
   ],
   "source": [
    "pred_df, true_df = eval_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mounted-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n",
    "\n",
    "for column in true_df:\n",
    "    #print('---------------------')\n",
    "    #print(\"Column : \" , column)\n",
    "    if column not in [\n",
    "            'Atelectasis',\n",
    "            'Cardiomegaly',\n",
    "            'Effusion',\n",
    "            'Infiltration',\n",
    "            'Mass',\n",
    "            'Nodule',\n",
    "            'Pneumonia',\n",
    "            'Pneumothorax',\n",
    "            'Consolidation',\n",
    "            'Edema',\n",
    "            'Emphysema',\n",
    "            'Fibrosis',\n",
    "            'Pleural_Thickening',\n",
    "                'Hernia']:\n",
    "        continue\n",
    "    actual = true_df[column]\n",
    "    #print( 'Actual : ' , actual)\n",
    "    pred = pred_df[\"prob_\" + column]\n",
    "    #print('Pred : ' , pred)\n",
    "    thisrow = {}\n",
    "    thisrow['label'] = column\n",
    "    thisrow['auc'] = np.nan\n",
    "    try:\n",
    "        thisrow['auc'] = sklm.roc_auc_score(\n",
    "        actual.values.astype(int), pred.values)\n",
    "        #auc_df = auc_df.append(thisrow, ignore_index=True)\n",
    "    #except Exception:\n",
    "        \n",
    "    except BaseException as e:\n",
    "        print(\"can't calculate auc for \" + str(column))\n",
    "        print(e)\n",
    "    auc_df = auc_df.append(thisrow, ignore_index=True)\n",
    "\n",
    "pred_df.to_csv(\"DenseNetpreds.csv\", index=False)\n",
    "auc_df.to_csv(\"DenseNetaucs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-conditioning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvproject_venv",
   "language": "python",
   "name": "dvproject_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
